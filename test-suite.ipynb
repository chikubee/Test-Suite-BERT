{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): BertLayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "tokenizer2 = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model2 = BertModel.from_pretrained('bert-base-uncased', output_hidden_states = True, output_attentions = True)\n",
    "model2.eval()\n",
    "\n",
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenized_text(text):\n",
    "    marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "    tokenized_text = tokenizer.tokenize(marked_text)\n",
    "    return tokenized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"here is some text to encode\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer, model is from PPB (pytorch pretrained bert), Tokenizer2, model2 is from Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 2182, 2003, 2070, 3793, 2000, 4372, 16044, 102]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = get_tokenized_text(text)\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(doc)\n",
    "indexed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  2182,  2003,  2070,  3793,  2000,  4372, 16044,   102]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([tokenizer2.encode(text, add_special_tokens=True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization is identical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoded Layers from Pytorch Pretrained Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_tokens = tokenizer.convert_tokens_to_ids(doc)\n",
    "segments_ids = [1] * len(doc)\n",
    "\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "with torch.no_grad():\n",
    "    encoded_layers, _ = model(tokens_tensor, segments_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor([[[ 0.1175, -0.0414, -0.0293,  ...,  0.0107,  0.0555,  0.0465],\n",
       "           [-0.8823,  0.6766, -1.4811,  ...,  0.2850,  0.5769,  0.4403],\n",
       "           [-0.8768, -0.7149, -0.6195,  ...,  0.1722,  0.0610,  0.3234],\n",
       "           ...,\n",
       "           [ 1.4578, -1.6513, -0.9443,  ..., -0.4543,  0.8893, -0.1556],\n",
       "           [ 0.6253, -0.6459,  0.1528,  ..., -0.1199, -0.1559,  0.7200],\n",
       "           [ 0.0278, -0.1232, -0.0390,  ...,  0.0574,  1.0494,  0.0589]]]),\n",
       "  tensor([[[-0.0271, -0.1631, -0.1662,  ...,  0.2235,  0.1752, -0.0263],\n",
       "           [-1.1879,  1.2727, -0.8647,  ..., -0.0647,  0.9201,  0.1990],\n",
       "           [-0.7484, -0.5935, -0.1351,  ...,  0.2642, -0.1155,  0.3915],\n",
       "           ...,\n",
       "           [ 1.7911, -1.1837, -0.6306,  ..., -1.1321,  1.0605, -0.3709],\n",
       "           [ 1.1517, -0.0946,  0.4455,  ..., -0.3401,  0.3848,  0.2715],\n",
       "           [-0.1580,  0.0727,  0.0607,  ...,  0.3485,  0.8295, -0.2014]]]),\n",
       "  tensor([[[ 0.0180, -0.2131, -0.0200,  ...,  0.1586,  0.1851,  0.0642],\n",
       "           [-1.4869,  0.9471, -0.5618,  ..., -0.0194,  0.7085,  0.2067],\n",
       "           [-0.7468, -0.7361, -0.2529,  ...,  0.1094, -0.4658,  0.4163],\n",
       "           ...,\n",
       "           [ 1.6166, -1.3820,  0.3142,  ..., -1.0061,  0.8823, -0.5760],\n",
       "           [ 0.7763,  0.0255,  0.1733,  ..., -0.2266, -0.3052,  0.0653],\n",
       "           [-0.0359, -0.0440,  0.1217,  ...,  0.1405,  0.1415, -0.0606]]]),\n",
       "  tensor([[[ 0.1262, -0.3385, -0.3248,  ...,  0.4711,  0.1743,  0.4087],\n",
       "           [-1.6223,  0.5553,  0.3927,  ..., -0.0130,  0.4494, -0.0070],\n",
       "           [-0.9624, -0.9612, -0.2230,  ..., -0.3796, -0.3728,  1.0661],\n",
       "           ...,\n",
       "           [ 1.5171, -1.0643,  0.0305,  ..., -1.0324,  0.9933, -0.7670],\n",
       "           [ 0.7622,  0.4104, -0.1139,  ..., -0.6871, -0.8677, -0.0733],\n",
       "           [-0.0276, -0.0220, -0.0091,  ...,  0.0558,  0.0549, -0.0337]]]),\n",
       "  tensor([[[ 0.0422, -0.4367, -0.1427,  ...,  0.1242,  0.3295,  0.5630],\n",
       "           [-1.5330,  0.2921,  0.2707,  ..., -0.0860,  0.2257,  0.1391],\n",
       "           [-0.6814, -0.8990, -0.6092,  ..., -0.2180, -0.1863,  1.2862],\n",
       "           ...,\n",
       "           [ 1.5022, -1.1582,  0.0884,  ..., -0.8143,  1.2343, -0.5921],\n",
       "           [ 0.7741,  0.6850,  0.1852,  ..., -0.3357, -0.9517,  0.0267],\n",
       "           [-0.0185, -0.0154, -0.0036,  ...,  0.0296, -0.0089, -0.0278]]]),\n",
       "  tensor([[[-0.0944, -0.3832, -0.3878,  ...,  0.1160,  0.0759,  0.7091],\n",
       "           [-1.4729, -0.0808, -0.2398,  ..., -0.4056, -0.2903,  0.4132],\n",
       "           [-1.1183, -1.0365, -0.5425,  ..., -0.4497, -0.5452,  1.0236],\n",
       "           ...,\n",
       "           [ 1.1764, -1.0096, -0.2906,  ..., -0.6431,  1.0549, -0.4821],\n",
       "           [ 0.9222,  0.7616,  0.3061,  ..., -0.3872, -0.9746, -0.0167],\n",
       "           [ 0.0114, -0.0070, -0.0169,  ...,  0.0124, -0.0350, -0.0328]]]),\n",
       "  tensor([[[-2.6928e-02, -6.5104e-01, -2.3532e-01,  ..., -1.1864e-01,\n",
       "             9.1892e-02,  6.9508e-01],\n",
       "           [-8.1716e-01, -1.6262e-02, -4.6249e-01,  ..., -1.2714e-01,\n",
       "            -1.1254e-01,  7.2116e-01],\n",
       "           [-8.7667e-01, -9.1460e-01, -2.4283e-01,  ..., -4.5745e-01,\n",
       "            -3.5690e-01,  1.2025e+00],\n",
       "           ...,\n",
       "           [ 1.0612e+00, -1.0693e+00, -6.1250e-02,  ..., -9.9542e-02,\n",
       "             1.2146e+00, -1.7856e-01],\n",
       "           [ 1.0725e+00,  2.3934e-01,  4.5823e-02,  ..., -5.3528e-01,\n",
       "            -8.1415e-01, -4.8460e-02],\n",
       "           [ 1.2693e-02, -7.1603e-03, -1.6280e-02,  ..., -9.6478e-03,\n",
       "            -1.0938e-03, -3.8214e-02]]]),\n",
       "  tensor([[[ 1.8094e-01, -4.7812e-01, -1.7687e-01,  ..., -2.2304e-01,\n",
       "            -2.1725e-01,  8.1849e-01],\n",
       "           [-4.9422e-01, -1.9835e-03, -4.4243e-01,  ..., -1.6025e-01,\n",
       "            -4.3555e-01,  7.4645e-01],\n",
       "           [-2.8721e-01, -7.8953e-01,  5.1238e-02,  ...,  6.9660e-02,\n",
       "            -2.4493e-01,  1.2048e+00],\n",
       "           ...,\n",
       "           [ 6.0426e-01, -5.9097e-01, -9.0057e-04,  ...,  7.2261e-02,\n",
       "             6.2375e-01, -2.1702e-01],\n",
       "           [ 7.5787e-01,  1.6946e-01,  3.6433e-01,  ..., -5.4298e-02,\n",
       "            -8.2953e-01,  7.2301e-02],\n",
       "           [ 3.4368e-02,  2.8611e-02,  3.8797e-02,  ..., -2.0167e-02,\n",
       "            -5.5116e-02, -3.9301e-02]]]),\n",
       "  tensor([[[ 0.0135,  0.1362,  0.0718,  ..., -0.4147, -0.1200,  1.1010],\n",
       "           [-0.6588,  0.2032, -0.1209,  ..., -0.1571, -0.1135,  0.6553],\n",
       "           [-0.2589, -0.3007,  0.0518,  ..., -0.0306, -0.1891,  1.0958],\n",
       "           ...,\n",
       "           [ 0.4178, -0.1356,  0.6914,  ..., -0.0433,  0.4328, -0.0893],\n",
       "           [ 0.4522,  0.5307,  0.5055,  ..., -0.4365, -0.5144,  0.0833],\n",
       "           [-0.0096,  0.0854,  0.0187,  ..., -0.0534, -0.0460,  0.0070]]]),\n",
       "  tensor([[[-6.1733e-01, -6.7391e-03, -2.8428e-02,  ..., -7.3193e-01,\n",
       "             1.3952e-01,  1.1758e+00],\n",
       "           [-7.3721e-01, -1.2742e-02,  2.7368e-01,  ..., -1.2457e-01,\n",
       "             8.6523e-02,  4.9912e-01],\n",
       "           [-5.5960e-01, -3.7140e-01,  3.8579e-01,  ..., -4.4652e-02,\n",
       "            -3.8036e-01,  1.2253e+00],\n",
       "           ...,\n",
       "           [-7.0131e-02,  5.8646e-02,  4.8844e-01,  ..., -3.5049e-01,\n",
       "             3.5317e-01, -4.3037e-01],\n",
       "           [ 7.0063e-02,  5.2042e-01, -5.3393e-02,  ..., -3.9171e-01,\n",
       "            -4.5683e-01, -1.0907e-01],\n",
       "           [-3.9641e-02, -2.2258e-02, -6.1312e-02,  ..., -1.1882e-03,\n",
       "            -5.7837e-03, -1.2959e-02]]]),\n",
       "  tensor([[[-0.4575, -0.0086, -0.3309,  ..., -0.2992, -0.1486,  0.8616],\n",
       "           [-0.8951, -0.1671, -0.2128,  ..., -0.7477, -0.1880,  0.6591],\n",
       "           [-0.7483, -0.4278, -0.1223,  ..., -0.4860, -0.2546,  1.5677],\n",
       "           ...,\n",
       "           [-0.1359,  0.0219,  0.1735,  ..., -0.5896,  0.1600,  0.8247],\n",
       "           [-0.0282,  0.5431, -0.0586,  ..., -0.7697, -0.4068,  0.4477],\n",
       "           [ 0.0463,  0.0279, -0.0467,  ...,  0.0067, -0.0155,  0.0043]]]),\n",
       "  tensor([[[-0.0999,  0.1383, -0.1502,  ..., -0.3454, -0.1062,  0.5856],\n",
       "           [-0.5939, -0.2450,  0.1604,  ..., -0.8229, -0.2931, -0.0184],\n",
       "           [-0.3535, -0.3209, -0.0436,  ..., -0.3214, -0.3533,  0.8083],\n",
       "           ...,\n",
       "           [ 0.2824,  0.3177,  0.4698,  ..., -0.5163, -0.3282,  0.8380],\n",
       "           [-0.0234,  0.6560, -0.1663,  ..., -0.8823, -0.2602,  0.2991],\n",
       "           [ 0.9546,  0.0632, -0.7010,  ..., -0.1023, -0.5826, -0.1377]]])],\n",
       " 12)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_layers, len(encoded_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor([tokenizer2.encode(text, add_special_tokens=True)])  # Add special tokens takes care of adding [CLS], [SEP], <s>... tokens in the right way for each model.\n",
    "with torch.no_grad():\n",
    "    all_hidden_states, all_attentions = model2(input_ids)[-2:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.1049, -0.0210, -0.0417,  ...,  0.0093,  0.0346,  0.0303],\n",
       "          [-0.7899,  0.9358, -1.3953,  ...,  0.2927,  0.5613,  0.5016],\n",
       "          [-0.8396, -0.5291, -0.5162,  ...,  0.1113,  0.1075,  0.3630],\n",
       "          ...,\n",
       "          [ 1.5062, -1.4110, -0.8548,  ..., -0.4749,  0.8963, -0.0522],\n",
       "          [ 0.6532, -0.4377,  0.2107,  ..., -0.1252, -0.1105,  0.7984],\n",
       "          [-0.0599, -0.1133, -0.0353,  ..., -0.2013,  0.8951, -0.0430]]]),\n",
       " tensor([[[-0.0125, -0.2191, -0.2090,  ...,  0.2493,  0.1552, -0.0491],\n",
       "          [-1.1062,  1.4273, -0.8342,  ...,  0.0458,  0.8728,  0.2475],\n",
       "          [-0.7080, -0.3701, -0.0666,  ...,  0.2603, -0.0469,  0.4278],\n",
       "          ...,\n",
       "          [ 1.8732, -0.9943, -0.6085,  ..., -0.9808,  0.9922, -0.2782],\n",
       "          [ 1.1598,  0.1219,  0.4285,  ..., -0.2322,  0.4805,  0.3791],\n",
       "          [-0.1454, -0.0715,  0.0495,  ...,  0.0927,  0.6526, -0.2409]]]),\n",
       " tensor([[[ 0.0568, -0.3138, -0.0495,  ...,  0.1891,  0.1856,  0.0601],\n",
       "          [-1.4235,  1.0459, -0.5484,  ...,  0.0371,  0.7450,  0.2760],\n",
       "          [-0.7372, -0.5837, -0.2064,  ...,  0.0892, -0.3151,  0.4585],\n",
       "          ...,\n",
       "          [ 1.6844, -1.1917,  0.3118,  ..., -0.9209,  0.9314, -0.4753],\n",
       "          [ 0.7751,  0.2236,  0.1933,  ..., -0.1294, -0.2306,  0.2596],\n",
       "          [-0.0529, -0.0967,  0.1262,  ...,  0.0594,  0.1242, -0.0619]]]),\n",
       " tensor([[[ 0.4397, -0.5062, -0.4454,  ...,  0.5209,  0.2806,  0.2868],\n",
       "          [-1.4901,  0.6474,  0.3552,  ...,  0.0215,  0.4400,  0.0225],\n",
       "          [-0.9102, -0.8042, -0.2107,  ..., -0.3050, -0.2221,  1.1011],\n",
       "          ...,\n",
       "          [ 1.5868, -0.8939, -0.0017,  ..., -0.9733,  0.9963, -0.6578],\n",
       "          [ 0.8364,  0.5085, -0.1553,  ..., -0.5408, -0.7100,  0.1625],\n",
       "          [-0.0252, -0.0492,  0.0070,  ...,  0.0192,  0.0594, -0.0463]]]),\n",
       " tensor([[[ 0.0569, -0.5780, -0.2238,  ...,  0.0114,  0.1940,  0.5635],\n",
       "          [-1.3874,  0.5260,  0.2635,  ..., -0.0288,  0.3106,  0.1403],\n",
       "          [-0.6322, -0.6748, -0.6627,  ..., -0.1624,  0.0463,  1.3279],\n",
       "          ...,\n",
       "          [ 1.6285, -0.9327,  0.0845,  ..., -0.7079,  1.3634, -0.5321],\n",
       "          [ 0.9629,  0.9213,  0.0225,  ...,  0.0613, -0.5885,  0.3259],\n",
       "          [-0.0165, -0.0340,  0.0147,  ...,  0.0157,  0.0061, -0.0467]]]),\n",
       " tensor([[[-0.0105, -0.6558, -0.4216,  ..., -0.0349,  0.1437,  0.5605],\n",
       "          [-1.3426,  0.2235, -0.2571,  ..., -0.2632, -0.2299,  0.4401],\n",
       "          [-0.9661, -0.7205, -0.6134,  ..., -0.2523, -0.3774,  1.0291],\n",
       "          ...,\n",
       "          [ 1.3212, -0.6529, -0.3280,  ..., -0.5569,  1.2748, -0.3605],\n",
       "          [ 0.9448,  0.9776,  0.1074,  ..., -0.0150, -0.4930,  0.2326],\n",
       "          [ 0.0141, -0.0356, -0.0137,  ...,  0.0030, -0.0244, -0.0428]]]),\n",
       " tensor([[[-0.0229, -0.7189, -0.1446,  ..., -0.5065,  0.1369,  0.5022],\n",
       "          [-0.7578,  0.1903, -0.5129,  ...,  0.0061, -0.0358,  0.7120],\n",
       "          [-0.8994, -0.6531, -0.3239,  ..., -0.3527, -0.0917,  1.2324],\n",
       "          ...,\n",
       "          [ 1.1317, -0.6975, -0.1448,  ..., -0.1536,  1.4315, -0.1199],\n",
       "          [ 1.0091,  0.3306, -0.2195,  ..., -0.4814, -0.3515,  0.1560],\n",
       "          [-0.0180, -0.0514, -0.0103,  ..., -0.0116,  0.0187, -0.0431]]]),\n",
       " tensor([[[ 0.1074, -0.4176, -0.2145,  ..., -0.6389,  0.1027,  0.6523],\n",
       "          [-0.5258,  0.1413, -0.6137,  ..., -0.2871, -0.3793,  0.6346],\n",
       "          [-0.4733, -0.4673, -0.1739,  ..., -0.1378, -0.0311,  1.0911],\n",
       "          ...,\n",
       "          [ 0.5277, -0.3361, -0.1417,  ..., -0.1268,  0.8558, -0.1407],\n",
       "          [ 0.5105,  0.2584,  0.1643,  ..., -0.2225, -0.5995,  0.3446],\n",
       "          [-0.0063, -0.0256,  0.0303,  ..., -0.0341, -0.0361, -0.0686]]]),\n",
       " tensor([[[ 2.4857e-01, -2.1932e-02, -3.7370e-02,  ..., -3.6126e-01,\n",
       "            1.4474e-01,  6.9255e-01],\n",
       "          [-4.7134e-01,  1.9586e-01, -1.7103e-01,  ..., -1.7025e-01,\n",
       "           -1.0587e-01,  6.8689e-01],\n",
       "          [-1.6725e-01, -2.5550e-01, -1.7528e-01,  ..., -4.6409e-02,\n",
       "           -1.7652e-02,  1.0921e+00],\n",
       "          ...,\n",
       "          [ 4.6499e-01, -6.1906e-02,  4.7222e-01,  ..., -1.0262e-01,\n",
       "            6.7133e-01,  6.8577e-02],\n",
       "          [ 2.4777e-01,  3.8729e-01,  1.9583e-01,  ..., -3.9096e-01,\n",
       "           -2.2897e-01,  2.7686e-01],\n",
       "          [-1.6986e-02, -9.2193e-04,  1.6010e-02,  ..., -6.1833e-02,\n",
       "           -4.9830e-02, -2.8033e-02]]]),\n",
       " tensor([[[-3.7535e-01, -2.6121e-04, -5.7053e-02,  ..., -5.0201e-01,\n",
       "           -3.7542e-01,  7.7305e-01],\n",
       "          [-3.1740e-01, -9.1049e-02,  2.8128e-02,  ..., -2.7747e-01,\n",
       "            2.7193e-01,  5.0948e-01],\n",
       "          [-1.0895e-01, -4.9731e-01,  2.4456e-01,  ..., -3.0577e-01,\n",
       "           -2.2568e-02,  1.2075e+00],\n",
       "          ...,\n",
       "          [ 3.0134e-01, -9.7508e-02,  3.3864e-01,  ..., -4.3701e-01,\n",
       "            5.7153e-01, -8.4879e-02],\n",
       "          [ 2.1152e-01,  2.5959e-01, -1.1089e-01,  ..., -4.4620e-01,\n",
       "           -1.3245e-01,  1.4252e-01],\n",
       "          [-4.4290e-02, -6.1789e-03, -5.5728e-02,  ...,  6.4444e-02,\n",
       "            1.4045e-02,  1.6627e-02]]]),\n",
       " tensor([[[-0.2782,  0.0311, -0.2785,  ..., -0.5399, -0.0360,  0.7443],\n",
       "          [-0.5486, -0.4670, -0.4370,  ..., -0.8938,  0.3610,  0.5551],\n",
       "          [-0.3356, -0.7329, -0.0635,  ..., -0.5607,  0.2282,  1.4912],\n",
       "          ...,\n",
       "          [ 0.2295, -0.1728,  0.0037,  ..., -0.5398,  0.4984,  0.9749],\n",
       "          [ 0.2009,  0.2687, -0.1824,  ..., -0.8054,  0.0557,  0.5920],\n",
       "          [ 0.0431,  0.0260, -0.0417,  ...,  0.0105, -0.0227,  0.0242]]]),\n",
       " tensor([[[-0.0549,  0.1053, -0.1065,  ..., -0.3551,  0.0686,  0.6506],\n",
       "          [-0.5759, -0.3650, -0.1383,  ..., -0.6782,  0.2092, -0.1639],\n",
       "          [-0.1641, -0.5597,  0.0150,  ..., -0.1603, -0.1346,  0.6216],\n",
       "          ...,\n",
       "          [ 0.2448,  0.1254,  0.1587,  ..., -0.2749, -0.1163,  0.8809],\n",
       "          [ 0.0481,  0.4950, -0.2827,  ..., -0.6097, -0.1212,  0.2527],\n",
       "          [ 0.9046,  0.2137, -0.5897,  ...,  0.3040, -0.6172, -0.1950]]]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_hidden_states[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LETS NOT GIVE SEGMENT IDS AS INPUT TO PPB MODEL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[ 0.1049, -0.0210, -0.0417,  ...,  0.0093,  0.0346,  0.0303],\n",
       "          [-0.7899,  0.9358, -1.3953,  ...,  0.2927,  0.5613,  0.5016],\n",
       "          [-0.8396, -0.5291, -0.5162,  ...,  0.1113,  0.1075,  0.3630],\n",
       "          ...,\n",
       "          [ 1.5062, -1.4110, -0.8548,  ..., -0.4749,  0.8963, -0.0522],\n",
       "          [ 0.6532, -0.4377,  0.2107,  ..., -0.1252, -0.1105,  0.7984],\n",
       "          [-0.0599, -0.1133, -0.0353,  ..., -0.2013,  0.8951, -0.0430]]]),\n",
       " tensor([[[-0.0125, -0.2191, -0.2090,  ...,  0.2493,  0.1552, -0.0491],\n",
       "          [-1.1062,  1.4273, -0.8342,  ...,  0.0458,  0.8728,  0.2475],\n",
       "          [-0.7080, -0.3701, -0.0666,  ...,  0.2603, -0.0469,  0.4278],\n",
       "          ...,\n",
       "          [ 1.8732, -0.9943, -0.6085,  ..., -0.9808,  0.9922, -0.2782],\n",
       "          [ 1.1598,  0.1219,  0.4285,  ..., -0.2322,  0.4805,  0.3791],\n",
       "          [-0.1454, -0.0715,  0.0495,  ...,  0.0927,  0.6526, -0.2409]]]),\n",
       " tensor([[[ 0.0568, -0.3138, -0.0495,  ...,  0.1891,  0.1856,  0.0601],\n",
       "          [-1.4235,  1.0459, -0.5484,  ...,  0.0371,  0.7450,  0.2760],\n",
       "          [-0.7372, -0.5837, -0.2064,  ...,  0.0892, -0.3151,  0.4585],\n",
       "          ...,\n",
       "          [ 1.6844, -1.1917,  0.3118,  ..., -0.9209,  0.9314, -0.4753],\n",
       "          [ 0.7751,  0.2236,  0.1933,  ..., -0.1294, -0.2306,  0.2596],\n",
       "          [-0.0529, -0.0967,  0.1262,  ...,  0.0594,  0.1242, -0.0619]]]),\n",
       " tensor([[[ 0.4397, -0.5062, -0.4454,  ...,  0.5209,  0.2806,  0.2868],\n",
       "          [-1.4901,  0.6474,  0.3552,  ...,  0.0215,  0.4400,  0.0225],\n",
       "          [-0.9102, -0.8042, -0.2107,  ..., -0.3050, -0.2221,  1.1011],\n",
       "          ...,\n",
       "          [ 1.5868, -0.8939, -0.0017,  ..., -0.9733,  0.9963, -0.6578],\n",
       "          [ 0.8364,  0.5085, -0.1553,  ..., -0.5408, -0.7100,  0.1625],\n",
       "          [-0.0252, -0.0492,  0.0070,  ...,  0.0192,  0.0594, -0.0463]]]),\n",
       " tensor([[[ 0.0569, -0.5780, -0.2238,  ...,  0.0114,  0.1940,  0.5635],\n",
       "          [-1.3874,  0.5260,  0.2635,  ..., -0.0288,  0.3106,  0.1403],\n",
       "          [-0.6322, -0.6748, -0.6627,  ..., -0.1624,  0.0463,  1.3279],\n",
       "          ...,\n",
       "          [ 1.6285, -0.9327,  0.0845,  ..., -0.7079,  1.3634, -0.5321],\n",
       "          [ 0.9629,  0.9213,  0.0225,  ...,  0.0613, -0.5885,  0.3259],\n",
       "          [-0.0165, -0.0340,  0.0147,  ...,  0.0157,  0.0061, -0.0467]]]),\n",
       " tensor([[[-0.0105, -0.6558, -0.4216,  ..., -0.0349,  0.1437,  0.5605],\n",
       "          [-1.3426,  0.2235, -0.2571,  ..., -0.2632, -0.2299,  0.4401],\n",
       "          [-0.9661, -0.7205, -0.6134,  ..., -0.2523, -0.3774,  1.0291],\n",
       "          ...,\n",
       "          [ 1.3212, -0.6529, -0.3280,  ..., -0.5569,  1.2748, -0.3605],\n",
       "          [ 0.9448,  0.9776,  0.1074,  ..., -0.0150, -0.4930,  0.2326],\n",
       "          [ 0.0141, -0.0356, -0.0137,  ...,  0.0030, -0.0244, -0.0428]]]),\n",
       " tensor([[[-0.0229, -0.7189, -0.1446,  ..., -0.5065,  0.1369,  0.5022],\n",
       "          [-0.7578,  0.1903, -0.5129,  ...,  0.0061, -0.0358,  0.7120],\n",
       "          [-0.8994, -0.6531, -0.3239,  ..., -0.3527, -0.0917,  1.2324],\n",
       "          ...,\n",
       "          [ 1.1317, -0.6975, -0.1448,  ..., -0.1536,  1.4315, -0.1199],\n",
       "          [ 1.0091,  0.3307, -0.2195,  ..., -0.4814, -0.3515,  0.1560],\n",
       "          [-0.0180, -0.0514, -0.0103,  ..., -0.0116,  0.0187, -0.0431]]]),\n",
       " tensor([[[ 0.1074, -0.4176, -0.2145,  ..., -0.6389,  0.1027,  0.6523],\n",
       "          [-0.5258,  0.1413, -0.6137,  ..., -0.2871, -0.3793,  0.6346],\n",
       "          [-0.4733, -0.4673, -0.1739,  ..., -0.1378, -0.0311,  1.0911],\n",
       "          ...,\n",
       "          [ 0.5277, -0.3361, -0.1417,  ..., -0.1268,  0.8558, -0.1407],\n",
       "          [ 0.5105,  0.2584,  0.1643,  ..., -0.2225, -0.5995,  0.3446],\n",
       "          [-0.0063, -0.0256,  0.0303,  ..., -0.0341, -0.0361, -0.0686]]]),\n",
       " tensor([[[ 2.4857e-01, -2.1932e-02, -3.7369e-02,  ..., -3.6126e-01,\n",
       "            1.4474e-01,  6.9255e-01],\n",
       "          [-4.7134e-01,  1.9586e-01, -1.7103e-01,  ..., -1.7025e-01,\n",
       "           -1.0587e-01,  6.8689e-01],\n",
       "          [-1.6724e-01, -2.5550e-01, -1.7528e-01,  ..., -4.6410e-02,\n",
       "           -1.7653e-02,  1.0921e+00],\n",
       "          ...,\n",
       "          [ 4.6499e-01, -6.1905e-02,  4.7222e-01,  ..., -1.0262e-01,\n",
       "            6.7133e-01,  6.8577e-02],\n",
       "          [ 2.4777e-01,  3.8729e-01,  1.9583e-01,  ..., -3.9096e-01,\n",
       "           -2.2897e-01,  2.7686e-01],\n",
       "          [-1.6986e-02, -9.2202e-04,  1.6010e-02,  ..., -6.1833e-02,\n",
       "           -4.9830e-02, -2.8033e-02]]]),\n",
       " tensor([[[-3.7535e-01, -2.6133e-04, -5.7052e-02,  ..., -5.0201e-01,\n",
       "           -3.7542e-01,  7.7305e-01],\n",
       "          [-3.1740e-01, -9.1050e-02,  2.8128e-02,  ..., -2.7747e-01,\n",
       "            2.7193e-01,  5.0948e-01],\n",
       "          [-1.0895e-01, -4.9731e-01,  2.4456e-01,  ..., -3.0577e-01,\n",
       "           -2.2568e-02,  1.2075e+00],\n",
       "          ...,\n",
       "          [ 3.0134e-01, -9.7508e-02,  3.3864e-01,  ..., -4.3701e-01,\n",
       "            5.7153e-01, -8.4879e-02],\n",
       "          [ 2.1152e-01,  2.5959e-01, -1.1089e-01,  ..., -4.4620e-01,\n",
       "           -1.3245e-01,  1.4252e-01],\n",
       "          [-4.4290e-02, -6.1790e-03, -5.5728e-02,  ...,  6.4444e-02,\n",
       "            1.4045e-02,  1.6627e-02]]]),\n",
       " tensor([[[-0.2782,  0.0311, -0.2785,  ..., -0.5399, -0.0360,  0.7443],\n",
       "          [-0.5486, -0.4670, -0.4370,  ..., -0.8938,  0.3610,  0.5551],\n",
       "          [-0.3356, -0.7329, -0.0635,  ..., -0.5607,  0.2282,  1.4912],\n",
       "          ...,\n",
       "          [ 0.2295, -0.1728,  0.0037,  ..., -0.5398,  0.4984,  0.9749],\n",
       "          [ 0.2009,  0.2687, -0.1824,  ..., -0.8054,  0.0557,  0.5920],\n",
       "          [ 0.0431,  0.0260, -0.0417,  ...,  0.0105, -0.0227,  0.0242]]]),\n",
       " tensor([[[-0.0549,  0.1053, -0.1065,  ..., -0.3550,  0.0686,  0.6506],\n",
       "          [-0.5759, -0.3650, -0.1383,  ..., -0.6782,  0.2092, -0.1639],\n",
       "          [-0.1641, -0.5597,  0.0150,  ..., -0.1603, -0.1346,  0.6216],\n",
       "          ...,\n",
       "          [ 0.2448,  0.1254,  0.1587,  ..., -0.2749, -0.1163,  0.8809],\n",
       "          [ 0.0481,  0.4950, -0.2827,  ..., -0.6097, -0.1212,  0.2527],\n",
       "          [ 0.9046,  0.2137, -0.5897,  ...,  0.3040, -0.6172, -0.1950]]])]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexed_tokens = tokenizer.convert_tokens_to_ids(doc)\n",
    "segments_ids = [1] * len(doc)\n",
    "\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "with torch.no_grad():\n",
    "    encoded_layers, _ = model(tokens_tensor)\n",
    "encoded_layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The results are same now with PPB and Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_concat_last_4_with_segment_ids(doc):\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(doc)\n",
    "    segments_ids = [1] * len(doc)\n",
    "\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        encoded_layers, _ = model(tokens_tensor, segments_tensors)  \n",
    "\n",
    "        token_embeddings = torch.stack(encoded_layers, dim=0)\n",
    "        token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "        token_embeddings = token_embeddings.permute(1,0,2)\n",
    "\n",
    "    token_vecs_cat = []\n",
    "    for token in token_embeddings:\n",
    "        cat_vec = torch.cat((token[-4], token[-3], token[-2], token[-1]), dim=0)\n",
    "        token_vecs_cat.append(cat_vec)\n",
    "    return token_vecs_cat\n",
    "\n",
    "def get_embeddings_concat_last_4_without_segment_ids(doc):\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(doc)\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        encoded_layers, _ = model(tokens_tensor)  \n",
    "\n",
    "        token_embeddings = torch.stack(encoded_layers, dim=0)\n",
    "        token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "        token_embeddings = token_embeddings.permute(1,0,2)\n",
    "\n",
    "    token_vecs_cat = []\n",
    "    for token in token_embeddings:\n",
    "        cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n",
    "        token_vecs_cat.append(cat_vec)\n",
    "    return token_vecs_cat\n",
    "\n",
    "def get_embeddings_transformers(text, tokenizer2, model2):\n",
    "    input_ids = torch.tensor([tokenizer2.encode(text, add_special_tokens=True)])  # Add special tokens takes care of adding [CLS], [SEP], <s>... tokens in the right way for each model.\n",
    "    with torch.no_grad():\n",
    "        all_hidden_states, all_attentions = model2(input_ids)[-2:]\n",
    "    pooled_output = torch.cat(tuple([all_hidden_states[i] for i in [-4, -3, -2, -1]]), dim=-1)\n",
    "    return pooled_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison in similarity of tokens for PPB with and without segment ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def get_cosine(a,b):\n",
    "    dot = np.dot(a, b)\n",
    "    norma = np.linalg.norm(a)\n",
    "    normb = np.linalg.norm(b)\n",
    "    cos = dot / (norma * normb)\n",
    "    return cos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "query1 = \"software\"\n",
    "query2 = \"smoking kills\"\n",
    "trans_query2 = get_tokenized_text(query2)\n",
    "vec2 = get_embeddings_concat_last_4_with_segment_ids(trans_query2)\n",
    "trans_query1 = get_tokenized_text(query1)\n",
    "vec1 = get_embeddings_concat_last_4_with_segment_ids(trans_query1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.672423 [CLS] [CLS]\n",
      "0.33314344 [CLS] smoking\n",
      "0.43435374 [CLS] kills\n",
      "-0.058492318 [CLS] [SEP]\n",
      "0.39661705 software [CLS]\n",
      "0.39606315 software smoking\n",
      "0.48784116 software kills\n",
      "0.025117889 software [SEP]\n",
      "-0.015437898 [SEP] [CLS]\n",
      "-0.0026445969 [SEP] smoking\n",
      "0.012134828 [SEP] kills\n",
      "0.9721178 [SEP] [SEP]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(vec1)):\n",
    "    for j in range(len(vec2)):\n",
    "        print(get_cosine(vec1[i], vec2[j]), trans_query1[i], trans_query2[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7332338 [CLS] [CLS]\n",
      "0.30889347 [CLS] smoking\n",
      "0.41676685 [CLS] kills\n",
      "-0.057872273 [CLS] [SEP]\n",
      "0.347957 software [CLS]\n",
      "0.35621607 software smoking\n",
      "0.60760146 software kills\n",
      "0.031820424 software [SEP]\n",
      "-0.024245258 [SEP] [CLS]\n",
      "-0.008735579 [SEP] smoking\n",
      "0.034555774 [SEP] kills\n",
      "0.971085 [SEP] [SEP]\n"
     ]
    }
   ],
   "source": [
    "query1 = \"software\"\n",
    "query2 = \"smoking kills\"\n",
    "trans_query2 = get_tokenized_text(query2)\n",
    "vec2 = get_embeddings_concat_last_4_without_segment_ids(trans_query2)\n",
    "trans_query1 = get_tokenized_text(query1)\n",
    "vec1 = get_embeddings_concat_last_4_without_segment_ids(trans_query1)\n",
    "for i in range(len(vec1)):\n",
    "    for j in range(len(vec2)):\n",
    "        print(get_cosine(vec1[i], vec2[j]), trans_query1[i], trans_query2[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# software got very similar to kills when segment ids are not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7137769 [CLS] [CLS]\n",
      "0.25000635 [CLS] software\n",
      "0.36119947 [CLS] engineering\n",
      "0.37555072 [CLS] skills\n",
      "-0.058984034 [CLS] [SEP]\n",
      "0.40880308 software [CLS]\n",
      "0.5280046 software software\n",
      "0.44189313 software engineering\n",
      "0.58193666 software skills\n",
      "0.022055043 software [SEP]\n",
      "-0.030546578 [SEP] [CLS]\n",
      "0.03651763 [SEP] software\n",
      "0.01451009 [SEP] engineering\n",
      "0.053263895 [SEP] skills\n",
      "0.9806409 [SEP] [SEP]\n"
     ]
    }
   ],
   "source": [
    "query1 = \"software\"\n",
    "query2 = \"software engineering skills\"\n",
    "trans_query2 = get_tokenized_text(query2)\n",
    "vec2 = get_embeddings_concat_last_4_without_segment_ids(trans_query2)\n",
    "trans_query1 = get_tokenized_text(query1)\n",
    "vec1 = get_embeddings_concat_last_4_without_segment_ids(trans_query1)\n",
    "for i in range(len(vec1)):\n",
    "    for j in range(len(vec2)):\n",
    "        print(get_cosine(vec1[i], vec2[j]), trans_query1[i], trans_query2[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6773981 [CLS] [CLS]\n",
      "0.2885203 [CLS] software\n",
      "0.41684645 [CLS] engineering\n",
      "0.41811934 [CLS] skills\n",
      "-0.06042074 [CLS] [SEP]\n",
      "0.39397994 software [CLS]\n",
      "0.636608 software software\n",
      "0.55451936 software engineering\n",
      "0.55175096 software skills\n",
      "0.025576958 software [SEP]\n",
      "-0.020932069 [SEP] [CLS]\n",
      "0.044678118 [SEP] software\n",
      "0.029137056 [SEP] engineering\n",
      "0.042281345 [SEP] skills\n",
      "0.9843705 [SEP] [SEP]\n"
     ]
    }
   ],
   "source": [
    "query1 = \"software\"\n",
    "query2 = \"software engineering skills\"\n",
    "trans_query2 = get_tokenized_text(query2)\n",
    "vec2 = get_embeddings_concat_last_4_with_segment_ids(trans_query2)\n",
    "trans_query1 = get_tokenized_text(query1)\n",
    "vec1 = get_embeddings_concat_last_4_with_segment_ids(trans_query1)\n",
    "for i in range(len(vec1)):\n",
    "    for j in range(len(vec2)):\n",
    "        print(get_cosine(vec1[i], vec2[j]), trans_query1[i], trans_query2[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7137769 [CLS] [CLS]\n",
      "0.25000635 [CLS] software\n",
      "0.36119947 [CLS] engineering\n",
      "0.37555072 [CLS] skills\n",
      "-0.058984034 [CLS] [SEP]\n",
      "0.40880308 software [CLS]\n",
      "0.5280046 software software\n",
      "0.44189313 software engineering\n",
      "0.58193666 software skills\n",
      "0.022055043 software [SEP]\n",
      "-0.030546578 [SEP] [CLS]\n",
      "0.03651763 [SEP] software\n",
      "0.01451009 [SEP] engineering\n",
      "0.053263895 [SEP] skills\n",
      "0.9806409 [SEP] [SEP]\n"
     ]
    }
   ],
   "source": [
    "query1 = \"software\"\n",
    "query2 = \"software engineering skills\"\n",
    "trans_query2 = get_tokenized_text(query2)\n",
    "vec2 = get_embeddings_concat_last_4_without_segment_ids(trans_query2)\n",
    "trans_query1 = get_tokenized_text(query1)\n",
    "vec1 = get_embeddings_concat_last_4_without_segment_ids(trans_query1)\n",
    "for i in range(len(vec1)):\n",
    "    for j in range(len(vec2)):\n",
    "        print(get_cosine(vec1[i], vec2[j]), trans_query1[i], trans_query2[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WHAT IS THE IMPLICATION OF THIS?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# this why i was getting bad results with Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
